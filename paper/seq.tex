\section{Sequentialization}
\label{sec:seq}

Section~\ref{sec:comp}'s compositional semantics gives an alternate way to
execute programs according to $\dfw(K)$, using
nondeterministic choice (in the instantiation of fresh task interfaces): rather
than storing tasks for later execution,
we simply guess the
global states that each task encounters at the beginning of its (up to
$K\!+\!1$) rounds, to obtain one possible $(K\!+\!1)$-length interface before 
resuming its caller. In essence, querying a task for its interface at
the point where it is called mimics the same control flow as a procedure call.
We exploit this fact to generate a sequential program
$@S(P,K)$ which simulates a given asynchronous program $P$ under the
$\dfw(K)$ scheduler; to obtain the interface of an
asynchronously-called task, $@S(P,K)$ \emph{calls} the task synchronously, with
the nondeterministically-guessed global states constituting the input values of
the task's interface. Figure~\ref{fig:seq:dfw} lists the statement-by-statement
translation $@S(P,K)$ of a program $P$; for simplicity, we
assume that there is one single global variable {\tt g}; the extension to
multiple global variables is straightforward, by multiplying the {\tt G}, {\tt
Guess}, {\tt Next}, and {\tt Save} variables.

\begin{figure}[t]
  \lstset{language=program}
  \lstset{basicstyle=\ttfamily\scriptsize}
  \begin{lstlisting}
    // translation of var g: $T$
    var G[$K$+1], Guess[$K$+1], Next[$K$+1]: $T$
    var delays: int

    // translation of proc $p$(l: $T$) $s$
    proc p(l: $T$, k: $K$+1)
      var Save: ([$K$+1]: $T$) * ([$K$+1]: $T$);
      $s'$ // i.e. the translation of $s$

    // translation of proc main() $s$
    proc main()
      const Init[$K$+1]: $T$ := G;
      var k: int := 0;
      delays := 0;
      Next := Guess := $\star$;
      $s'$; // i.e. the translation of $s$
      assume G = Guess;
      assume Init[1..$K$+1] = Next[0..$K$]

    // translation of access to g
    G[k]

    // translation of call x := p e
    call (x,k) := p(e,k)

    // translation of return e
    return (e,k)

    // translation of async t := p e
    Save := (G, Guess);
    G := Next;
    Next := Guess := $\star$;
    call t := p(e,k);
    assume G = Guess;
    G, Guess := Save

    // translation of x := wait t
    assume G = Guess;
    G := Next;
    Next := Guess := $\star$;
    x, k' := t; k := max(k,k')

    // at each possible preemption
    if ($\star$ && delays < K)
      delays := delays+1; k := k+1
  \end{lstlisting}    
  \caption{The $K$-delay sequentialization $@S(P,K)$.}
  \label{fig:seq:dfw}
\end{figure}

Our sequentialization $@S(P,K)$ essentially encodes the interfaces of the
previous section using the global {\tt G}, {\tt Guess}, and {\tt Next}
variables, along with the {\tt Save} procedure-local variables, and the {\tt
Init} constant of the {\sf main} procedure. Initially, the root task, defined
by the {\tt main} procedure, guesses the global values it will encounter at the
first point at which it either returns, or waits for a task to complete; this
value is stored in both {\tt Next} and {\tt Guess}, and corresponds to the
output values of interface $I$ in the compositional semantics of
Figure~\ref{fig:sem:comp}; the input values of $I$ are stored in {\tt Init}. If
the root procedure encounters a \lstinline{wait} statement, then it validates
its {\tt Guess}, advances its state to {\tt Next}, where its previously-called
subtasks have left off, and guesses the next global values at which it will
either return or encounter a \lstinline{wait} statement; this process
corresponds to composing the $I$ and $J_1$ interfaces in the {\sc CWait} rule
of the compositional semantics, effectively sequencing the effects of
previously-called tasks before resuming from the \lstinline{wait} statement.

The other key interesting aspect of $@S(P,K)$ is the translation of the
\lstinline{async} statement. Similar to the sequentialization of the
$\df(K)$ scheduler~\cite{conf/popl/EmmiQR11}, the procedure of an
asynchronous task is called \emph{synchronously}, using the values {\tt Next}
of the global variables effected by previously-called asynchronous procedures;
furthermore, the global values guessed to be left behind by the called task are
stored into {\tt Next}, from which subsequently-called tasks will resume.

While the global values reachable in the $K$-delay sequentialization $@S(P,K)$
of a program $P$ are not directly comparable to those of $P$, since the global
variables of $@S(P,K)$ are $(K\!+\!1)$-length vectors of values, we can compare
values using a projection function $@p$ mapping $@S(P,K)$'s configurations to
values of $P$. In particular, we define $@p(c)$ as $\mathtt{Next[}K\mathtt{]}(c)$,
i.e.,~the valuation of the {\tt Next} vector's last element in $c$; then we
define $R_{@p}(P) = \set{ @p(c) : c_0 -> .. -> c \text{ is finalized}}$. Given
this projection, we can show that the projected reachable global values
in the $K$-delay sequentialization $@S(P,K)$ of an asynchronous program $P$ are
precisely equal to the values reachable in $P$ in the $K$-bounded
compositional semantics.

\begin{lemma}
  \label{lem:seq:eq:comp}
  $R_{@p}(@S(P,K)) = \tilde{R}(P,K)$.
\end{lemma}

Combining Lemmas~\ref{lem:dfw:eq:comp} and~\ref{lem:seq:eq:comp}, we have
equivalence between the valuations reachable under the $\dfw(K)$ scheduler with
those reachable in the sequential program $@S(P,K)$.

\begin{theorem}
  $R(P,\dfw(K)) = R(@S(P,K))$.
\end{theorem}
